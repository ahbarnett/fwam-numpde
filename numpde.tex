% FWAM lecture. Func Approx & PDE. CCM beamer template.
%
% Build:
% pdflatex -shell-escape numpde; bibtex numpde; pdflatex numpde
%
% (here -shell-escape lets it call epstopdf to convert .eps to .stuff.pdf)

\documentclass[t]{beamer}
\usepackage[utf8]{inputenc}
\usepackage{epstopdf}  % handle EPS

\usepackage{multimedia,hyperref}   % embeds but needs external movie files

\usepackage{bm,tcolorbox}

% Alex's macros for beamer. Use macros to let you type less stuff
\newcommand{\ft}[1]{\frametitle{#1}}
% note: can't make macros for begin/end frame: http://tex.stackexchange.com/questions/326787/difficulty-in-creating-macro-newcommand-for-the-beginning-and-end-of-frames-i

% frame box on next slide
\newcommand<>{\tmpbox}[1]{
    \definecolor{colorbox}{RGB}{255,255,255}
    \only#2{\definecolor{colorbox}{RGB}{255,128,0}}
    \tcbox[left=0pt,right=0pt,top=0pt,bottom=0pt,colback=white,colframe=colorbox,nobeforeafter,tcbox raise base]{#1}
}
% https://tex.stackexchange.com/questions/186044/how-a-framebox-will-appear-around-the-text-on-a-click

\input{rgb}
\newcommand{\lb}[1]{{\color{blue}#1}}    % from prosper azure titles
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\ben}{\begin{enumerate}}
\newcommand{\een}{\end{enumerate}}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}
\newcommand{\mbf}[1]{{\bm #1}}           % requires bm package
\newtheorem{thm}{Theorem}
\newcommand{\ig}[2]{\includegraphics[#1]{#2}}
\newcommand{\tbox}[1]{{\mbox{\tiny #1}}}
\newcommand{\cbox}[1]{{\mbox{\scriptsize #1}}}
%\newcommand{\who}[1]{{\tiny \textcolor{green}{(#1)}}}
\newcommand{\who}[1]{{\scriptsize \textcolor{darkgreen}{(#1)}}}
\newcommand{\whoc}[1]{{\scriptsize \textcolor{darkgreen}{#1}}} % use w/ \cite
\newcommand{\com}[1]{{\scriptsize \textcolor{purple}{#1}}}      % comment
\newcommand{\co}[1]{\mbox{\scriptsize \tt \textcolor{black} #1}}          % code
\newcommand{\vg}{\vspace{2ex}}
\newcommand{\sg}{\vspace{1ex}}
\newcommand{\hg}{\vspace{0.5ex}}
\newcommand{\gb}{\ensuremath{\textcolor{darkgreen}{\bullet\;}}\ }
\newcommand{\bmp}[1]{\begin{minipage}{#1}}
\newcommand{\bmpt}[1]{\begin{minipage}[t]{#1}}
\newcommand{\emp}{\end{minipage}}
\newcommand{\pig}[2]{\bmp{#1}\includegraphics[width=#1]{#2}\emp} % mp-fig, nogap
\newcommand{\pigm}[3]{\bmp{#1}\href{#3}{\includegraphics[width=#1]{#2}}\emp} % w/ movie
\newcommand{\ora}[1]{{\color{orange} #1}}
\newcommand{\gre}[1]{{\color{green} #1}}
\newcommand{\yel}[1]{{\color{yellow} #1}}
\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\sr}[1]{{\scriptsize #1}}
\newcommand{\vt}[2]{\biggl[\begin{matrix}#1\\#2\end{matrix}\biggr]} % 2-col-vec
\newcommand{\mt}[4]{\biggl[\begin{matrix}#1&#2\\#3&#4\end{matrix}\biggr]} %2x2

% macros for this work
\newcommand{\RR}{\mathbb{R}}
\newcommand{\sfrac}[2]{\mbox{\small $\frac{#1}{#2}$}}
\newcommand{\half}{\sfrac{1}{2}}
\newcommand{\bigO}{{\mathcal O}}
\newcommand{\eps}{\varepsilon}
\newcommand{\x}{\mbf{x}}
\newcommand{\y}{\mbf{y}}


\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\re}{Re}

\title{FWAM Session B: Function Approximation and Differential Equations}
\date{Wed, 10/30/19}
\author{\textbf{Alex Barnett}\inst{1} and \textbf{Keaton Burns}\inst{1,2}}
\institute{\inst{1} Center for Computational Mathematics, Flatiron Institute\\
  \inst{2} Center for Computational Mathematics, Flatiron Institute,
  and Department of Mathematics, MIT
}

\usetheme{CCM}
\setbeamertemplate{bibliography item}{\gb}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}


% ---------------------------------------------------
\begin{frame}\ft{LECTURE 1: interpolation, integration, spectral methods}

  
  \lb{Motivations}

  exact func.\ $f(x)$ described by $\infty$ number of points

  how handle approximately (but accurately) in computer, using least cost (bytes)? 
  \bi

\item
  Interpolation:

given exact data $f(x_i)$ at some $x_i$, model $f(x)$ at other points $x$?

  cheap but accurate look-up table for expensive $f(x)$

\quad\com{Contrast: fit noisy data = 
  learning (pdf for) params in model, via likelihood/prior}

\item (Numerical) integration:

  eg computing expectation values given a pdf, or their quantum version

\quad\com{Contrast: Monte Carlo (random, high-dim.) integration, Thurs am}
  
\item Differentiation:

  \com{get gradient $\nabla f$: for optimization, or get matrix which approx.\ an ODE/PDE}
  
\item Spectral (often Fourier) methods:

If $f(x)$ is smooth, handle very accurately without much extra cost

\ei

Deterministic (non-random) methods.

Integr/diff crucial for numerical ODEs and PDEs \com{topic of LECTURE II}

\end{frame}


% ---------------------------------------------------
\begin{frame}\ft{Goals for LECTURE I}

TODO
  
  teach range of practical methods focusing on 1D

  pointers to dimensions $d>1$

\sg
  
  Concepts:

  convergence order \quad  \com{how does accuracy improve w/ number of
    discretization points?}

  global \qquad \com{(one expansion formula for the whole domain)}

  \quad vs local \quad \com{(different expansions for $x$ in different regions)}

  spectral method \quad \com{global, often use FFT, converge very fast}
    %er than any fixed order}
%    $N^{-p}$ for any $p$}
  
  adaptivity \quad \com{automatically placing degrees of freedom only where they need to be}

  rounding error \& catastrophic cancellation \quad \com{how not shoot self in the foot}

\vg
  
  interpolation = func.\ representation, is key to all else

  
\end{frame}


% ---------------------------------------------------
\begin{noframe}\ft{Interpolation in 1D ($d=1$)}

\bmp{3in}
  Say $y_j = f(x_j)$ known at nodes $\{x_j\}$ \quad \com{$N$-pt ``grid''}

  exact data, not noisy
  
  want interpolant $\tilde f(x)$, s.t.\ $\tilde f(\x_j)=y_j$
  \emp
  \hfill
\pig{1.5in}{figs/fsamp}

\pause
\sg

\bmp{3.9in}
  hopeless w/o assumptions on $f$, eg smoothness, otherwise\dots

  \gb extra info helps, eg $f$ periodic, or $f(x) = \mbox{smooth}\cdot|x|^{-1/2}$
  \emp
  \hfill
\pig{.5in}{figs/fcrazy}

\pause
\vg

\bmp{3in}
\lb{Simplest}: use value at $x_j$ nearest to $x$

\hfill
\com{``snap to grid''}
%\com{$h=x_{j+1}-x_j$}

Error $\max_x|\tilde f(x)-f(x)| = \bigO(h)$ as $h\to 0$

\quad \com{holds if $f'$ bounded; ie $f$ can be nonsmooth but not crazy}
  
\emp
\hfill
\pig{1.4in}{figs/fsnap}

\sg

\gre{Recall %asymptotic
notation
  ``$\bigO(h)$'': exists $C,h_0>0$ s.t.\ error $\le Ch$ for all $h<h_0$}

\pause
\vg

\bmp{3in}
\lb{Piecewise linear}:

\hfill \com{``connect the dots''}

max error $ = \bigO(h^2)$ as $h\to 0$

\quad \com{needs $f''$ bounded, ie smoother than before}
  
\emp
\hfill
\pig{1.4in}{figs/flin}

\vg

Message: a higher order method is only higher order if $f$ smooth enough

\end{noframe}



% ---------------------------------------------------
\begin{noframe}\ft{Interlude: convergence rates}

  Should know or measure convergence rate of any method you use

\gb ``effort'' parameter $N$ \hfill \com{eg \# grid-points = $1/h^d$ where $h = $ grid spacing,  $d=$ dim}

We just saw algebraic conv.\ error $=\bigO(N^{-p})$, for order $p=1,2$

\pause

Is only one graph in numerical analysis: \framebox{``relative error vs effort''}

\sg

\pig{2.2in}{figs/convloglog}
\pause
\hfill
\pig{2.2in}{figs/convlinlog}
\pause

\sg

Note how spectral gets many digits for small $N$
\hfill \com{crucial for eg 3D prob.}
%Let's say a 3D prob.\ must have $N\le 300$: here spectral is 

\com{``spectral'' = ``superalgebraic'', $\bigO(N^{-k})$ for any $k$}

\gb how many digits to you want? \com{for 1-digit (10\% error), low order ok, easier to code}

\vg

\mbox{{\tt <rant>}
test your code w/ {\em known exact soln} to check error conv.
{\tt <\textbackslash rant>} }

\quad \com{What is the prefactor $C$ in error $\le Ch^k$ ? Has asymp.\ rate even kicked in yet? :)}

%You may not believe your model, but at least should trust its soln

\end{noframe}

% ---------------------------------------------------
\begin{frame}\ft{Higher-order interpolation for smooth $f$: the local idea}

  For any target $x$, use only set of nearest $p$ nodes:

  \bmp{2.9in}

  Exists unique degree-$(p{-}1)$ poly, $\sum_{k=0}^{p-1} c_k x^k$
  
  \quad which matches local data $(x_j,y_j)_{j=1}^p$
  
  \quad \com{generalizes piecewise lin. idea}

  \quad \com{do \red{not} eval poly outside its central region!}
  
  \emp
  \hfill
  \pig{1.6in}{figs/flocpoly}
  
  \gb error $\bigO(h^{p})$, ie high order, but $\tilde f$ {\em not} continuous ($\tilde f \notin C$) \hfill\com{has small jumps}

  \quad \com{if must have cont, recommend splines, eg cubic $p=3$:
    $\tilde f\in C^2$, meaning $\tilde f''$ is cont.}
%   as target $x$ moves, ``jumps'' to another poly,
  
\pause

\vg

\lb{How to find the degree-$(p{-}1)$ poly?}

1) crafty: solve square lin sys for coeffs\quad 
$\sum_{k<p} x_j^k c_k = y_j$ \hfill \com{ $j=1,\dots,p$}

\qquad ie $V\mbf{c} = \y$ \qquad \com{$V$=''Vandermonde'' matrix, is ill-cond.\ but works}

2) traditional: barycentric formula
$\displaystyle \tilde f(x) = \frac{\sum_{j=1}^p \frac{y_j}{x-x_j}w_j}{\sum_{j=1}^p \frac{1}{x-x_j}w_j}$
\bmp{1in}

\hfill \com{$w_j = \frac{1}{\prod_{i\neq j}(x_j-x_i)}$}

\vg

\hfill\whoc{\cite[Ch.~5]{ATAP}}
\emp

\sg

Either way, $\tilde f(x) = \sum_{j=1}^p y_j \ell_j(x)$
where $\ell_j(x)$ is $j$th Lagrange basis func:

\qquad \pig{2in}{figs/lag}


\end{frame}

% ---------------------------------------------------
\begin{noframe}\ft{Global polynomial (Lagrange) interpolation?}

  Want increase order $p$. Use {\em all} data, get single $\tilde f(x)$, so $p=N$?
  \hfill\com{``global''}

  $p=N=32$, smooth (analytic) $f(x) = \frac{1}{1+9x^2}$ on $[-1,1]$ : \hfill\who{Runge 1901}
  
  \pig{2.2in}{figs/demopoly1}
  \hfill
  \uncover<3->{
  \pig{2.2in}{figs/demopoly2}
  }
  
\pause
  \gb warning: \red{unif.\ grid, global interp.\ fails} \; \com{$\rightarrow$ only use locally in central region}
%  interval $[a,b]$

  \pause
  \bmp{2.9in}
  But exists good choice of nodes\ldots

\hg
  
  ``Chebychev'': \com{means non-unif.\ grid density $\sim \frac{1}{\sqrt{1-x^2}}$}

  \gb our first spectral method % basis of higher-dim $d>1$ methods\ldots

\quad   max err $=\bigO(\rho^{-N})$
\hfill \com{exponential conv!}
  
\quad \com{  $\rho>1$ ``radius'' of largest
  ellipse in which $f$ analytic}
  
\emp
\hfill
  \pig{1.65in}{figs/bern}

% * give the rate rho = 1.39.. ?  x=1i/3; rho=abs(x + sqrt(x^2-1)), rho^-32
  
% * Lebesgue const?

  
  
\end{noframe}

\begin{noframe}\ft{Node choice and adaptivity}

Recap: poly approx.\ $f(x)$ on $[a,b]$ has good \& bad node sets $\{x_j\}_{j=1}^N$

\sg

  \lb{Question}: Do you get to {\em choose} the set of nodes at which $f$ known?

\sg
  
  \gb data fitting applications: No \com{(or noisy variants: kriging, Gaussian processes, etc)}

  \qquad \com{use local poly (central region only!), or something stable (eg splines)} \whoc{\cite{GCbook}}
  
  \gb almost all else, interp., quadrature, PDE solvers: Yes
  \hfill \com{so pick good nodes!}

  \pause
  \vg
  
\lb{Adaptivity idea}
\hfill \com{global is \red{inefficient} if $f$ smooth in most places, but not everywhere}

\pause
\sg

 \only<3>{ \pig{3.2in}{figs/adap1} }
 \pause
 \pig{3.2in}{figs/adap2}
 \hfill
 \bmp{1.2in}
% Given tolerance $\eps$ (eg $10^{-12}$)

 automatically split
 
(recursively) panels

 until max err $\le\epsilon$

\sg
 
 \com{via tests for local error}
 
 \emp

\vg
 
1D adaptive interpolator codes to try:

 \gb {\tt github/dbstein/function\_generator}
 \; \com{py+numba, fast} \hfill \who{Stein '19}

 \gb {\tt chebfun} for MATLAB\;
\com{big-$p$ Cheb.\ grids can exploit FFTs!}
\hfill  \who{Trefethen et al.}

\sg
 
App.:  replace nasty expensive $f(x)$ by cheap one! \hfill \com{optimal ``look-up table''}


\end{noframe}
    
% ---------------------------------------------------
\begin{frame}\ft{Global interpolation of periodic functions I}

  \com{Just did $f$ on intervals $[a,b]$. \;
    global interp.\ (\& integr., etc.) of smooth {\em periodic} $f$ differs!}

\hg

  Periodic: 
  $f(x+2\pi)=f(x)$ for all $x$, \quad $f(x) = \sum_{n\in\mathbb{Z}} \hat f_k e^{ikx}$
  \hfill \com{Fourier series}

\pause
  
  Instead of poly's, use \ora{truncated} series \;
  $\tilde f(x) = \sum_{|k|<N/2} c_k e^{ikx}$ \hfill\com{``trig.\ poly''}

  \sg

  \pause
\bmp{2in}
What's best you can do?

\quad get $N$ coeffs right $c_k=\hat f_k$

\sg

\quad error $\sim$ size of tail $\{\hat f_k\}_{|k|\ge N/2}$
\emp
\hfill
\pig{2.6in}{figs/fhat}

%\vspace{-1ex}

\pause

How read off $c_k$ from {\em samples} of $f$ on a grid?

\quad \com{uniform grid best (unlike for poly's!); non-uniform needs
  linear solve, slow $\bigO(N^3)$ effort}

%  How read off $\mbf{c} := \{c_k\}_{k=-N/2}^{N/2-1}$ from values $\y := \{f(x_j)\}_{j=1}^N$ at nodes?

  Uniform grid $x_j=\frac{2\pi j}{N}$, \; set
  $c_k  = \frac{1}{N}\sum_{j=1}^N e^{ikx_j} f(x_j)$ \hfill
  \com{simply $\mbf{c}=FFT[\mbf{f}]$}

\pause
  
\quad easy to show $c_k = \dots + \hat f_{k-N} + \hat f_k + \hat f_{k+N} + \hat f_{k+2N} + \dots$

\hfill $ = \; \hat f_k$ \com{ desired }
$+ \;\sum_{m\neq 0}\hat f_{k+mN}$ \;\com{ aliasing error, small if tail small}
%  due to discrete sampling}

\sg
\pause

Summary: given $N$ samples $f(x_j)$, interp.\ error = truncation + aliasing

\quad a crude bound is $\displaystyle\max_{x\in[0,2\pi)} |\tilde f(x)-f(x)| \le 2\sum_{|k|\ge N/2} |\hat f_k|$

\quad \com{ie error controlled by sum of tail}

\end{frame}


  % ---------------------------------------------------
\begin{noframe}\ft{Global interpolation of periodic functions II}

  As grow grid $N$, how accurate is it?
  \hfill 
  \com{just derived err $\sim$ sum of $|\hat f_k|$ in tail $|k|\ge N/2$}

\sg
  
  \quad \com{Now \;\; $\hat f_k = \frac{1}{2\pi}\int_{0}^{2\pi} f(x) e^{-ikx}dx =
  \frac{1}{2\pi}\int_{0}^{2\pi} f^{(p)}(x) \frac{e^{-ikx}}{(ik)^p}dx$
\hfill integr.\ by parts $p$ times}

\sg
  
  So for a periodic $f\in C^p$, \; \com{recall first $p$ derivs of $f$ bounded}
  
  %has $p$ bounded derivs
  \qquad $\hat f_k=\bigO(k^{-p})$, tail sum $\bigO(N^{1-p})$ %=\bigO(h^{p-1})$
  \;\;\com{$(p{-}1)$th order acc.}
  \hfill\who{better: \cite{tref}}
  % \;(could tweak)}

\vg
\pause

Example of: \hfill \framebox{$f$ smoother \;$\leftrightarrow$\; faster $\hat f_k$ tail decay \;$\leftrightarrow$\; faster convergence}

\pause

\sg

Even smoother case: $f$ analytic,\quad
\com{so $f(x)$ analytic in some complex strip $|\im x|\le \alpha$}

\quad then $\hat f_k = \bigO(e^{-\alpha|k|})$, exp.\ conv.\ $\bigO(e^{-\alpha N/2})$
\hfill \com{(fun proof: shift the contour)} 

\quad \com{as with Bernstein ellipse, to get exp.\ conv.\ {\em rate} need understand $f$ {\em off its real axis} (wild!)}

\sg
\pause

Smoothest case: ``band-limited'' $f$ with $\hat f_k=0$, $|k|>k_\tbox{max}$,

\quad then interpolant {\em exact} once $N>2k_\tbox{max}$

\vg

That's theory. In real life you always \ora{measure} your conv.\ order/rate!

\sg

Take-home: for $f$ smooth \& periodic, unif. grid global spectral acc.\

\gb use FFTs, cost $\bigO(N\log N)$, to go between $f(x_j)$ \com{grid} \& $\hat f_k$ \com{Fourier coeffs}

\end{noframe}



% ---------------------------------------------------
\begin{noframe}\ft{Flavor of interpolation in higher dims $d>1$}

  \bmp{2.2in}
  If you {\em can} choose the nodes:

  \quad tensor product of 1D interp.

  \quad either global

  \quad or adaptively refined boxes %(quad-tree)
  
  \emp
  \pig{1in}{figs/2dugrid_lab}
  \quad
  \pig{0.9in}{figs/2dadaptgrid}
    
  \hspace{2.2in}
  \com{periodic, global}
  \hspace{.3in}
  \com{adaptive $p=6\times 6$ Cheby}

%\hfill\who{Babb et al '18}  but this is generic

\vg
\pause

  \bmp{2.1in}
If {\em cannot} choose the nodes:
  
  interp.\ $f(\x)$ from scattered data $\{\x_i\}$ is hard

\sg
  
  \com{Eg google terrain: $f(\x)$ rough $\rightarrow$ v.\ low ord,}
% Bavarian pre-alps

\quad \com{see amusing transition in interp.\ type:}


\vg

Or if know $f$ smooth

\quad \com{fit local multivariate polynomial}

  If $f$ noisy and smooth, many methods

  kriging, kernels, ***



  \emp
  \hfill
  \pig{2.2in}{figs/gterrain_lab}
  
 \end{noframe}

% ---------------------------------------------------
\begin{frame}\ft{Numerical integration (back to $d=1$)}

  Task: eval.\ $\int_a^b f(x) dx$ accurately w/ least number of func.\ evals, $N$

\sg
  
``quadrature'': nodes $\{x_j\}$, weights $\{w_j\}$, s.t.
$\int_a^b f(x) dx \approx \sum_{j=1}^N w_j f(x_j)$

\sg
  
%Here, usually user gets to choose nodes $x_j$ \hfill\com{so pick best ones!}

Idea: \; get interpolant $\tilde f$ thru data $f(x_j)$ $\rightarrow$ {\em
    integrate that exactly}

\hfill  \com{``intepolatory quadrature''}

\pause
\vspace{-1ex}

\bmp{3.3in}
Examples:

\gb local piecewise linear $\rightarrow$ composite trapezoid rule

   \qquad \com{$w_j=h$ except $h/2$ at ends. \; low-order, err $\bigO(N^{-2})$, avoid!}
   \emp
   \hfill
   \pig{0.9in}{figs/trap}

\sg
   
   \gb $N$-node global poly $\rightarrow$ gives
% unique
   $\{w_j\}$ integrating degree $N{-}1$ exactly

   \qquad \com{err $\bigO(\rho^{-N})$ \hfill solve lin sys
     $V^T \mbf{w} = \{\int_a^b x^k dx\}_{k=0}^{N-1}$
     %\{monomial integrals\}
   } \; \who{Newton--Coates}

\sg
   
   \gb better: ``Gaussian'' $\{x_j,w_j\}$ integrates deg.\ $2N{-}1$
   exactly! \hfill \com{err $\bigO(\rho^{-2N})$}

Adaptive quadrature (Gauss in each panel) excellent: \com{codes {\tt quadgk}, {\tt scipy}, etc}

\sg
\pause

\gb periodic case: $x_j=\frac{2\pi j}{N}$, $w_j=\frac{2\pi}{N}$ excellent
\quad \com{``periodic trap.\ rule''}

\qquad \com{easy to check integrates $e^{ikx}$ exactly for $|k|<N$, ``Gaussian''}

\qquad \com{$f$ analytic in $|\im x|<\alpha$ gives exp.\ conv.\ $\bigO(e^{-\alpha N})$, twice as good as interp!}

\pause

\quad demo: {\tt \small N=14; sum(exp(cos(2*pi*(1:N)/N)))/N - besseli(0,1)}

\hspace{1in} {\tt \small ans = 1.3e-15}

  
\end{frame}


% ---------------------------------------------------
\begin{frame}\ft{Advanced integration}

  \gb custom quadr.\ for singularity \; \com{eg $f(x) = \mbox{smooth}\cdot|x|^{-1/2}$}

  \qquad or for a new set of funcs.\ \com{``gen. Gaussian quad.''}
\hfill \who{CCM: Manas Rachh}

\gb high-order end-corrections to trap.\ rule \hfill \who{Alpert '99}
 
\vdots

%\gb changes of variables \com{eg sinh-tanh transform to remove endpoint singularities}

\sg
\pause

\lb{Higher dimensions $d>1$}

For $d$ a few, tensor products of 1D $n$-node grids in each dim

\com{other coord systems, eg sphere, can use tensor product in $(\theta,\phi)$}

\com{adaptivity works: subdivide into boxes} \com{same pic as for interp.}
    
\vg
  
  \lb{Much higher $d\gg 1$}

  Now exponential cost $N=n^d$ kills you :(

  Are ``sparse grids'' scaling better \com{rely on funcs aligning w/ axes}
  
  Monte Carlo methods: sum $N$ values of $f(\x_j)$ for $\x_j$ random points
  
  \quad error $= \bigO(N^{-1/2})$  \com{1/2-order acc, indep of dim $d$}

*** check
  
 % \quad \com{Note MCMC does not easily give $\int f(\x) d\x$, just ratios of such}

  
\end{frame}

% ---------------------------------------------------
\begin{noframe}\ft{Numerical differentiation}

  Task: given ability to eval.\ $f(\x)$ anywhere, how get $\nabla f(\x)$ ?
  \hfill\com{assume smooth}

%\qquad \com{obviously again we have to assume $f$ smooth!}
\sg
\pause

\lb{Finite differencing} idea, 1D:\;\; $f'(x) = \frac{f(x+h)-f(x-h)}{2h} + \bigO(h^2)$
\hfill\com{Taylor's thm}


\bmp{1.8in}
Want smallest error:

suggests taking $h\to 0$ ?

\vg

Let's see how that goes\ldots
\vspace{10ex}

\emp
\pause
\hfill\pig{2.7in}{figs/fderr}

\sg

\gb shrinking $\bigO(h^2)$ error gets swamped by a new growing error\dots what?

\pause

\gb CPU arithmetic done only to relative ``rounding error'' $\epsilon_\tbox{mach}\sim 10^{-16}$

\gb subtracting v. close $f(x+h)$ and $f(x-h)$: ``catastrophic cancellation''

\gb balance two error types: $h_\tbox{best} \sim (\epsilon_\tbox{mach})^{1/3} \sim 10^{-5}$

\sg

\com{Reading: floating point, backward stability}\; \whoc{\cite[Ch.~5--6]{GCbook} \cite[Ch.~12--15]{nla}}

\end{noframe}


% ---------------------------------------------------
\begin{noframe}\ft{Differentiation in $d=1$}

As w/ integration: get interpolant $\rightarrow$ differentiate it exactly
\hfill \whoc{\cite[Ch.~6]{tref}}

\quad \com{get $p\times p$ matrix $D$, simple formula, acting on func.\ values $\{f(x_j)\}$ to give $\{f'(x_j)\}$}

\sg

\bmp{1.4in}
Examples:

\sg

\quad \com{$N$ Chebychev nodes}

\quad \com{in $[-1,1]$}

\sg

shown: max error in $f'$

\vspace{20ex}

\emp
\hfill
\pig{3in}{figs/trefchebdiff_lab.png}

\sg

\gb for $N$ large, dense $D$ is never formed, instead applied via FFT


\end{noframe}


% ---------------------------------------------------
\begin{frame}\ft{Summary: we scratched the surface}

Can integrate \& differentiate functions given only point values $f(x_j)$

\sg

Both follow from building a good interpolant

\sg

For $f$ smooth in 1D, can \& should easily get {\em many} (10+) digits accuracy

\vspace{4ex}

\lb{Concepts:}

\sg

  convergence order/rate

  smoothness

  spectral method
  
  global vs local
  
  adaptivity

  rounding error \& catastrophic cancellation

  tensor products for 2D \& 3D; higher gets harder
  
\vspace{4ex}

See references at end of slide, and come ask us stuff!

\end{frame}





% ---------------------------------------------------
\begin{frame}\ft{LECTURE II: numerical differential equations}

GOALS

***

\end{frame}

% ---------------------------------------------------
\begin{noframe}\ft{Reminder of types and applications of diff.\ eq.}

% feel free to scratch/edit, but some overview is needed
  
\gb  ODEs: \; \com{eg pendulum} $u''(t) + \sin(u(t)) = 0$
 \hfill \com{task: solve $u(t)$ efficiently \& acc.}

  \qquad needs initial conditions to kick it off \quad \com{eg $u(0)=1$, $u'(0)=0$}

 \qquad \com{eg kinetics of system of well-mixed chemicals, $\mbf{u}(t)$ is vector}
  
\sg

\gb time-independent PDEs, usually ``elliptic'' \hfill \com{Mike will explain}

\qquad \com{eg Poisson eqn} \; $\Delta u = g$,
\hfill \com{ $u(\x)=$ %equilibrium
  chemical concentration or electric potential}

%  eg what electric potential caused by bunch of charges surrounded by H$_2$O ?
%  (protein electrostatics)

  \qquad \com{$\x$ means $(x,y,\dots)$, \quad $\Delta u$ means Laplacian $\partial^2 u/\partial x^2 + \partial^2 u/\partial y^2 + \dots = $ curvature of $u$}


  \hfill \com{$g(\x) = $ volume source of chemical or charge}

  
\qquad needs boundary conditions (BCs) on $u$, or decay at infinity

\qquad \com{ eg viscous fluid flow: $\mbf{u}$ is velocity field, Stokes eqns}
  
\qquad \com{ eg what is ground state of quantum system? solving t-indep.\ Schr\"odinger\; $\Delta u = Eu$}

\sg

\gb time-dependent (evolution) PDEs \quad $u(\x,t)$ varies in space and time

\qquad \com{eg heat/diffusion equation} \; $\partial u /\partial t + \Delta u= g$
\hfill \com{$g(\x,t)=$ source}

\qquad needs initial and BCs \;\com{BCs may vary in time\ldots}

\sg

  [Mike will in next talk overview the three flavors of PDE]

  \sg

BCs: simple (eg periodic cube) vs complicated ($u=0$ on a nasty surface)

  
\end{noframe}

% ---------------------------------------------------
\begin{frame}\ft{IVPs to BVPs}

Motivate focus on BVPs by mentioning:

\gb Most people familiar with method of lines

\gb Equivalent ``propagator'' approach: discretize time, then solve BVP

\gb Most timesteppers are FD methods (some examples)

\end{frame}

% ---------------------------------------------------
\begin{frame}\ft{Finite difference methods}

Basic viewpoint:

\gb Construct Taylor-series approximation to value at neighboring points

\gb For N points, expand to (N-1) derivatives (error $\bigO(h^N)$)

\gb Eliminate system to get approximation to $d$-th derivative ($d < N$) (error $\bigO(h^{N-d})$)

\sg

Alternate viewpoint:

\gb Differentiate the unique interpolating polynomial of deg N-1

Illustrate with centered forward 1st-order scheme, centered 2nd-order scheme (get extra degree for free).

\end{frame}

% ---------------------------------------------------
\begin{frame}\ft{Timestepping with finite difference methods}

Consider temporal ODE $u'(t) = f(u(t))$

Explicit methods: simple, just require evaluating $f(u_n)$.

\gb E.g. Forward Euler: use 1st-order forward difference rule

\com{Unstable for large timesteps}

\bea
u'(t) = - \lambda u(t) \quad \lambda > 0 \\
\frac{u_{n+1} - u_n}{k} = - \lambda u_n \\
u_{n+1} = (1 - k \lambda) u_n \\
\boxed{k \lambda < 2}
\eea

Implicit methods: stable, but require solving $f(u^{n+1}) = ...$

\gb Backward Euler: use 1st-order backward difference rule

\com{Stability, but potentially at high cost}

\bea
u'(t) = - \lambda u(t) \quad \lambda > 0 \\
\frac{u_{n+1} - u_n}{k} = - \lambda u_{n+1} \\
u_{n+1} = (1 + k \lambda)^{-1} u_n \\
\eea

\end{frame}

% ---------------------------------------------------
\begin{frame}\ft{Advanced finite difference techniques}

  % do you go to 2D & 3D here? or earlier?

\hfill\pig{0.8in}{figs/fd}  

\gb Selecting stencils term by term (e.g. upwinding)

\gb Adaptive stencil selection (e.g. WENO)

\vspace{2em}

Resources: ...

Codes: ...

\end{frame}

% ---------------------------------------------------
\begin{frame}\ft{Finite element methods}

  \bmp{3.5in}
Partition domain into elements, represent unknown within each element using basis functions (usually polynomials)
\emp
\hfill
\pig{1.1in}{figs/fem}

Convert equations to weak form

\gb Give example

\gb Weak form advantages: lowers order, works if lower derivs are integrable (good for discontinuities, hyperbolic), can use tent functions

Replace weak form with Galerkin/weighted-residual form to get algebraic system

Traditional FEM methods use tent functions, produce continuous solutions.  Fluxes at cell boundaries can be computed from internal representation, but can be discontinuous (non conservative).

\end{frame}

% ---------------------------------------------------
\begin{frame}\ft{Finite volume methods}

Case of FEM taking functions to be piecewise constant inside elements

Resulting system is exactly conservative (good for hyperbolic), but requires Riemann solve

\gb Order increased by using neihgbors to reconstruct higher order internal representations or fluxes (slope/flux reconstruction)

\gb Reconstruction is nonlinear to control oscillations around discontinuities (TVD, ENO/WENO).

Very common in CFD, CCA

\end{frame}

% ---------------------------------------------------
\begin{frame}\ft{Advanced finite element methods}

\gb Discontinuous Galerkin: allow discontinuities, need Riemann solvers again

\gb Spectral elements: move towards large p for better internal representations

Resources: ...

Codes: ...

\end{frame}

% ---------------------------------------------------
\begin{frame}\ft{Spectral methods}

  % can refer back to D matrix, which was nodes-to-nodes.
  % intro idea of Cheby basis ($\approx$ FFT of node values)
  
Limit of very few elements with very large p: exponential accuracy for smooth problems

Traditional techniques: Fourier spectral methods.

\gb Fast due to FFT: optimal complexity with exponential accuracy

\gb Limited to simple geometries / equations with symmetries

Polynomial spectral methods

\gb More flexible in terms of equations

\gb Still limited to simple geometries: cubes, spheres, cylinders, etc.

\gb Still a weak method, but don't integrate by parts. Apply Galerkin directly.

Modern research: sparse methods for arbitrary equations.

Resources: ...

Codes: ...

\end{frame}

% ---------------------------------------------------
\begin{frame}\ft{Boundary integral methods}

\bmp{3.5in}  
Use knowledge of PDEs in constructing numerical solutions:

A Green's func $G$ (fundamental soln) needed

eg $\Delta G = \delta$
\emp
\hfill\pig{1.1in}{figs/bie}

For linear PDEs dominated by boundary rather than bulk terms, compute solution by forming integral equation of the fundamental solution/Green's function. Reduced dimensionality. Improved conditioning. Low-rank interactions and fast methods. Reconstruct solution in the bulk.

Examples: Stokes flow, Helmholtz, Maxwell, typically with homogeneous media

heavily uses high-order integration methods

\gb see Jun Wang's talk later today!

\end{frame}

% ---------------------------------------------------
\begin{frame}\ft{}

\end{frame}

% ---------------------------------------------------
\begin{frame}\ft{References}

\bibliographystyle{amsalpha}  % abbrv
\bibliography{numpde}
  
\end{frame}



\end{document}
